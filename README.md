Team Name: Live Vision

Team Members: John Sheffield, Alhasan Mohsen, and Andrew Palmertree

Description of the project: 
My team and I had an idea to help deaf people and visual listeners connect more easily with the world. 
Our original idea was to use an AR headset to capture the world around the user and place text above each person’s head who is talking near the user. 
However, my team had to pivot since the AR headset display didn’t look professional, and we ended up using an Android app to simulate the AR experience. 
We developed the app using Android Studios. We were able to develop the app to convert speech to text in real-time and used Google’s Detect Faces API to set the text above the people.
